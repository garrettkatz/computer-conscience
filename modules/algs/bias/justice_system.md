---
layout: default
---

# Justice System: Discussion Questions

1. The readings list four reasons for criminal sentencing- retribution, deterrence, incapacitation, and rehabilitation- and argue that existing sentencing algorithms only emphasize incapacitation.  What would an algorithm that took a more holistic view of imprisonment look like?

2. How can we train judges and prosecutors to use the algorithms in ways that will reduce discrimination and mass incarceration? What should be the role of law schools in this process?

3. Was the response by Wu, et al. to criticisms of their criminality paper convincing?

4. The ProPublica standard of fairness is something like: “Members of different groups should have the same probability of being placed in the wrong group.”  The Northpointe standard of fairness is something like: “Individuals with the same score should have the same probability of reoffending, regardless of their group membership.”  If the two groups have different overall probabilities of reoffending, it is not possible to accomplish both at the same time!  Which standard of fairness is more reasonable?  Try looking at it from both the perspective of the judge as well as the perspective of the defendant.

5. We’ve talked a lot about “proxies”: features that are themselves not protected, but are correlated with protected features.  For example, COMPAS should not (and does not) use race as a feature, but it might use things like address, education level, etc. that are correlated with race.  We can say that proxies that are heavily correlated with protected features (like race or religion) should not be used- but what if the characteristic you are trying to predict is itself highly correlated with a protected feature (like crime is with race)?  How do you decide which proxies are ok?  

6. One of the issues that has come up repeatedly is transparency.  There are two arguments against transparency when it comes to sentencing/predictive policing/etc.  (1) These algorithms are proprietary, and if the company makes them public then no one would pay them for the software.  (2) If we release details of how decisions are made, then the algorithms are easier to “trick”.  What expectation of transparency is reasonable?

7. Consider the Wu and Zhang reading about whether one can predict criminality by examining a person’s facial features.  The authors of that paper could have done many things better from a scientific perspective.  But even if they had collected data, set up their experiments, etc. perfectly, would it still have been a bad thing to do?  In other words, do you think it’s ever the case that some questions simply shouldn’t be asked?  
