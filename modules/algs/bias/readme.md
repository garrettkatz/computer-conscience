---
layout: default
---

# Algorithmic Discrimination and Bias

This readme and supporting files can also be viewed directly in the github repository [here](https://github.com/garrettkatz/computer-conscience/tree/master/modules/algs/bias).

## Module Info:

**_Format:_** Reading list and discussion/reaction guides

**_Area:_** Machine learning and data mining

**_Technical Content:_** Knowledge of statistics and probability, basic knowledge of machine learning classifiers.  Note: For less technically-mature populations (e.g., those that have not taken a machine learning course), the articles marked with a (\*) may be excluded.

**_Ethical Content:_** Discrimination in US and EU law, technical and societal notions of disparate impact, use of statistics to identify discrimination, use of algorithms in the justice system and by law enforcement, use of algorithms for “scoring” individuals, bias in online advertising.

## Overview

In this module, students will read a collection of articles from the popular press, humanities journals, and technical venues.  Content will span a range of topics related to algorithmic discrimination and bias, including examples of how use of algorithms can cause harm, how to identify discrimination, and techniques for correcting bias in algorithms.

This module is intended to cover several days of reading and discussions/reactions, and is organized by topic.  If limited by time or otherwise desired, the instructor may select a subset of topics to cover.  

## Requirements

To fully complete this module, students should have experience with probability, statistics, and machine learning.  Less advanced courses can skip the articles marked with (\*).

## Instructor Preparation:

For each topic below, we list the approximate amount of class time required.  Approximately a week before each class, the instructor should assign the specified readings.  The discussion questions can be used in class, assigned beforehand for written reaction papers, or both, depending on course structure.

### Topics:

- Introduction to Algorithmic Discrimination (2 days)

    * **_Readings:_** 

        - [https://medium.com/@mrtz/how-big-data-is-unfair-9aa544d739de](https://medium.com/@mrtz/how-big-data-is-unfair-9aa544d739de)
        - [https://journals.sagepub.com/doi/pdf/10.1177/2053951716679679](https://journals.sagepub.com/doi/pdf/10.1177/2053951716679679)
        - [https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2477899](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2477899)
        - [https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/2016_0504_data_discrimination.pdf](https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/2016_0504_data_discrimination.pdf)
        - [http://www.mlandthelaw.org/papers/goodman1.pdf](http://www.mlandthelaw.org/papers/goodman1.pdf)


    * **_Discussion/reaction topics:_** [Introduction to Bias](introduction_to_bias.html)

- Algorithms in the Justice System (2 days)

    * **_Readings_**:

        - [http://www.datacivilrights.org/pubs/2015-1027/Courts_and_Predictive_Algorithms.pdf](http://www.datacivilrights.org/pubs/2015-1027/Courts_and_Predictive_Algorithms.pdf)
        - [https://arxiv.org/pdf/1611.04135.pdf](https://arxiv.org/pdf/1611.04135.pdf)
        - [https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
        - [https://heinonline.org/HOL/Page?handle=hein.journals/fedpro80&div=21&g_sent=1&casa_token=qkoqIhK30TcAAAAA:ZZqFYtVnPij0aaq7Bz74ytRypErrQu5Pm7hE9ijKD7Iuajz40UsSr4dFxYj7bItVlfuIhZo&collection=journals](https://heinonline.org/HOL/Page?handle=hein.journals/fedpro80&div=21&g_sent=1&casa_token=qkoqIhK30TcAAAAA:ZZqFYtVnPij0aaq7Bz74ytRypErrQu5Pm7hE9ijKD7Iuajz40UsSr4dFxYj7bItVlfuIhZo&collection=journals)
        - [https://www.nature.com/articles/s41562-017-0141](https://www.nature.com/articles/s41562-017-0141)
        - [https://www.nytimes.com/2017/12/02/opinion/sunday/intelligent-policing-and-my-innocent-children.html?smprod=nytcore-iphone&smid=nytcore-iphone-share&_r=1](https://www.nytimes.com/2017/12/02/opinion/sunday/intelligent-policing-and-my-innocent-children.html?smprod=nytcore-iphone&smid=nytcore-iphone-share&_r=1)

    * **_Discussion/reaction topics:_** [Justice System](justice_system.html)

- Algorithms for Scoring and Advertising (1 day)

    * **_Readings_**:

        - [https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2376209](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2376209)
        - [https://heinonline.org/HOL/Page?handle=hein.journals/washlr89&div=44&g_sent=1&casa_token=&collection=journals](https://heinonline.org/HOL/Page?handle=hein.journals/washlr89&div=44&g_sent=1&casa_token=&collection=journals)
        - [https://dataprivacylab.org/projects/onlineads/1071-1.pdf](https://dataprivacylab.org/projects/onlineads/1071-1.pdf)

    * **_Discussion/reaction topics:_** [Scoring and Advertising](scoring_advertising.html)

- Detecting and Correcting Bias (1-2 days)

    * **_Readings_**:

        - [https://journals.sagepub.com/doi/abs/10.1177/0162243915605575](https://journals.sagepub.com/doi/abs/10.1177/0162243915605575)
        - [https://www.cmu.edu/dietrich/philosophy/docs/london/IJCAI17-AlgorithmicBias-Distrib.pdf](https://www.cmu.edu/dietrich/philosophy/docs/london/IJCAI17-AlgorithmicBias-Distrib.pdf)
        - [http://sorelle.friedler.net/papers/kdd_disparate_impact.pdf](http://sorelle.friedler.net/papers/kdd_disparate_impact.pdf) (\*)
        - [https://arxiv.org/pdf/1701.08230.pdf](https://arxiv.org/pdf/1701.08230.pdf) (\*)

    * **_Discussion/reaction topics:_** [Correcting Bias](correcting_bias.html)

## Debrief:

After the readings and discussions/reactions have been completed, consider having the students share their written reactions with one another and as a class, discuss the main takeaway messages.